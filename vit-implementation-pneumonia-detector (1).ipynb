{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T22:51:53.699276Z","iopub.execute_input":"2021-07-25T22:51:53.699642Z","iopub.status.idle":"2021-07-25T22:51:56.941294Z","shell.execute_reply.started":"2021-07-25T22:51:53.699559Z","shell.execute_reply":"2021-07-25T22:51:56.938754Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nfrom tensorflow.keras import datasets ,layers,models\nimport matplotlib.pyplot as plt\nfrom keras.applications import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.applications import *\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:25.694975Z","iopub.execute_input":"2021-10-02T12:23:25.695386Z","iopub.status.idle":"2021-10-02T12:23:25.704705Z","shell.execute_reply.started":"2021-10-02T12:23:25.695349Z","shell.execute_reply":"2021-10-02T12:23:25.703526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 1\ninput_shape = (1000, 1000, 3)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:26.365711Z","iopub.execute_input":"2021-10-02T12:23:26.366123Z","iopub.status.idle":"2021-10-02T12:23:26.370358Z","shell.execute_reply.started":"2021-10-02T12:23:26.366085Z","shell.execute_reply":"2021-10-02T12:23:26.369347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = image.load_img(\"../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0001-0001.jpeg\")\nimg","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:27.65739Z","iopub.execute_input":"2021-10-02T12:23:27.657961Z","iopub.status.idle":"2021-10-02T12:23:28.506624Z","shell.execute_reply.started":"2021-10-02T12:23:27.657906Z","shell.execute_reply":"2021-10-02T12:23:28.50527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:28.508363Z","iopub.execute_input":"2021-10-02T12:23:28.5088Z","iopub.status.idle":"2021-10-02T12:23:29.11379Z","shell.execute_reply.started":"2021-10-02T12:23:28.508765Z","shell.execute_reply":"2021-10-02T12:23:29.1126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport cv2\nimg_num = cv2.imread(\"../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0001-0001.jpeg\")\nimg_num.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:29.115859Z","iopub.execute_input":"2021-10-02T12:23:29.116338Z","iopub.status.idle":"2021-10-02T12:23:29.325259Z","shell.execute_reply.started":"2021-10-02T12:23:29.116295Z","shell.execute_reply":"2021-10-02T12:23:29.324017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_num","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:29.910027Z","iopub.execute_input":"2021-10-02T12:23:29.910506Z","iopub.status.idle":"2021-10-02T12:23:29.916414Z","shell.execute_reply.started":"2021-10-02T12:23:29.910477Z","shell.execute_reply":"2021-10-02T12:23:29.915756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### train = ImageDataGenerator(rescale = 1/255)\ntrain = ImageDataGenerator(rescale=1./255,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\n\nvalid = ImageDataGenerator(rescale=1./255,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:30.593024Z","iopub.execute_input":"2021-10-02T12:23:30.59364Z","iopub.status.idle":"2021-10-02T12:23:30.602306Z","shell.execute_reply.started":"2021-10-02T12:23:30.593604Z","shell.execute_reply":"2021-10-02T12:23:30.601293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train.flow_from_directory(\n        '../input/chest-xray-pneumonia/chest_xray/train/',\n        target_size=(1000, 1000),  \n        class_mode='binary')\nvalidation_dataset = valid.flow_from_directory(\n        '../input/chest-xray-pneumonia/chest_xray/val/',\n        target_size=(1000, 1000),\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:34.628105Z","iopub.execute_input":"2021-10-02T12:23:34.62846Z","iopub.status.idle":"2021-10-02T12:23:39.249858Z","shell.execute_reply.started":"2021-10-02T12:23:34.62843Z","shell.execute_reply":"2021-10-02T12:23:39.248755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.class_indices\nimg_size =1000","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:40.880359Z","iopub.execute_input":"2021-10-02T12:23:40.880745Z","iopub.status.idle":"2021-10-02T12:23:40.885051Z","shell.execute_reply.started":"2021-10-02T12:23:40.880701Z","shell.execute_reply":"2021-10-02T12:23:40.884001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#    **load pre-trained EfficientNetB6 baseline model with the imagNet Dataset **","metadata":{}},{"cell_type":"code","source":"\nconv_base = EfficientNetB6(input_shape=(img_size,img_size,3),include_top=False,weights=\"imagenet\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:58:46.493216Z","iopub.execute_input":"2021-08-14T10:58:46.493591Z","iopub.status.idle":"2021-08-14T10:58:55.203145Z","shell.execute_reply.started":"2021-08-14T10:58:46.493557Z","shell.execute_reply":"2021-08-14T10:58:55.20224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # **base-line Model**","metadata":{}},{"cell_type":"code","source":"cnn4 = Sequential()\ncnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)))\ncnn4.add(BatchNormalization())\n\ncnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(MaxPooling2D(pool_size=(2, 2)))\ncnn4.add(Dropout(0.25))\n\ncnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(Dropout(0.25))\n\ncnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(MaxPooling2D(pool_size=(2, 2)))\ncnn4.add(Dropout(0.25))\n\ncnn4.add(Flatten())\n\ncnn4.add(Dense(512, activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(Dropout(0.5))\n\ncnn4.add(Dense(128, activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(Dropout(0.5))\n\ncnn4.add(Dense(1, activation='sigmoid'))\n\n\ncnn4.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T13:06:25.442318Z","iopub.execute_input":"2021-08-14T13:06:25.442632Z","iopub.status.idle":"2021-08-14T13:06:25.597289Z","shell.execute_reply.started":"2021-08-14T13:06:25.442602Z","shell.execute_reply":"2021-08-14T13:06:25.594203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n                                            patience = 2,\n                                            verbose=1,\n                                            factor=0.1,\n                                            min_lr=0.000001)\ncnn4.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy'])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T13:06:26.993163Z","iopub.execute_input":"2021-08-14T13:06:26.993508Z","iopub.status.idle":"2021-08-14T13:06:27.00758Z","shell.execute_reply.started":"2021-08-14T13:06:26.993479Z","shell.execute_reply":"2021-08-14T13:06:27.006556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = cnn4.fit(train_dataset, validation_data=validation_dataset, epochs = 15, callbacks = [learning_rate_reduction])\nhistory","metadata":{"execution":{"iopub.status.busy":"2021-08-14T13:06:30.92733Z","iopub.execute_input":"2021-08-14T13:06:30.927737Z","iopub.status.idle":"2021-08-14T13:34:40.487324Z","shell.execute_reply.started":"2021-08-14T13:06:30.927696Z","shell.execute_reply":"2021-08-14T13:34:40.486474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = valid.flow_from_directory(\n        '../input/chest-xray-pneumonia/chest_xray/test/',\n        target_size=(224, 224),\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2021-08-14T13:51:23.938521Z","iopub.execute_input":"2021-08-14T13:51:23.938867Z","iopub.status.idle":"2021-08-14T13:51:24.051774Z","shell.execute_reply.started":"2021-08-14T13:51:23.938831Z","shell.execute_reply":"2021-08-14T13:51:24.050884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Evaluate on test data\")\nresults = cnn4.evaluate(test_dataset)\nprint(\"test loss, test acc:\", results)\nprint(\"Accuracy of the model is - \" , results[1]*100 , \"%\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T13:51:25.228509Z","iopub.execute_input":"2021-08-14T13:51:25.228833Z","iopub.status.idle":"2021-08-14T13:51:38.636914Z","shell.execute_reply.started":"2021-08-14T13:51:25.228802Z","shell.execute_reply":"2021-08-14T13:51:38.635929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # **VGG16 Model**","metadata":{}},{"cell_type":"code","source":"# Create the base model of VGG19\nvgg19 = VGG19( include_top=False, input_shape = (224, 224, 3) , weights = 'imagenet')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:11:44.931609Z","iopub.execute_input":"2021-08-16T23:11:44.93194Z","iopub.status.idle":"2021-08-16T23:11:45.375456Z","shell.execute_reply.started":"2021-08-16T23:11:44.931907Z","shell.execute_reply":"2021-08-16T23:11:45.374265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:11:45.863694Z","iopub.execute_input":"2021-08-16T23:11:45.864082Z","iopub.status.idle":"2021-08-16T23:11:45.881698Z","shell.execute_reply.started":"2021-08-16T23:11:45.864049Z","shell.execute_reply":"2021-08-16T23:11:45.880876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### ","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nfor layer in vgg16.layers[:-1]: # this is where I changed your code\n    model.add(layer)    \n# Freeze the layers \n#for layer in model.layers:\n#    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:11:47.744614Z","iopub.execute_input":"2021-08-16T23:11:47.744948Z","iopub.status.idle":"2021-08-16T23:11:47.839106Z","shell.execute_reply.started":"2021-08-16T23:11:47.744917Z","shell.execute_reply":"2021-08-16T23:11:47.838256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(64 , activation = 'relu'))\nmodel.add(Dense(32 , activation = 'relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:11:48.620482Z","iopub.execute_input":"2021-08-16T23:11:48.620821Z","iopub.status.idle":"2021-08-16T23:11:48.654805Z","shell.execute_reply.started":"2021-08-16T23:11:48.620789Z","shell.execute_reply":"2021-08-16T23:11:48.654031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:11:49.628152Z","iopub.execute_input":"2021-08-16T23:11:49.628495Z","iopub.status.idle":"2021-08-16T23:11:49.647197Z","shell.execute_reply.started":"2021-08-16T23:11:49.628466Z","shell.execute_reply":"2021-08-16T23:11:49.64642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\nmodel.compile(optimizer = opt, loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryCrossentropy()])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:35:04.296847Z","iopub.execute_input":"2021-08-16T23:35:04.297219Z","iopub.status.idle":"2021-08-16T23:35:04.314131Z","shell.execute_reply.started":"2021-08-16T23:35:04.297184Z","shell.execute_reply":"2021-08-16T23:35:04.31337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=validation_dataset, epochs = 5, batch_size = 64)\nhistory","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:35:05.167724Z","iopub.execute_input":"2021-08-16T23:35:05.168114Z","iopub.status.idle":"2021-08-16T23:43:32.730857Z","shell.execute_reply.started":"2021-08-16T23:35:05.168076Z","shell.execute_reply":"2021-08-16T23:43:32.727935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = valid.flow_from_directory(\n        '../input/chest-xray-pneumonia/chest_xray/test/',\n        target_size=(224,224),\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:32:31.041078Z","iopub.execute_input":"2021-08-16T23:32:31.041415Z","iopub.status.idle":"2021-08-16T23:32:31.151125Z","shell.execute_reply.started":"2021-08-16T23:32:31.041384Z","shell.execute_reply":"2021-08-16T23:32:31.150299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Evaluate on test data\")\nresults = model.evaluate(test_dataset)\nprint(\"test loss, test acc:\", results)\nprint(\"Accuracy of the model is - \" , results[1]*100 , \"%\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:32:32.015808Z","iopub.execute_input":"2021-08-16T23:32:32.016152Z","iopub.status.idle":"2021-08-16T23:32:44.944198Z","shell.execute_reply.started":"2021-08-16T23:32:32.01612Z","shell.execute_reply":"2021-08-16T23:32:44.943237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\n# plot loss during training\npyplot.subplot(211)\npyplot.title('Loss')\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\n# plot accuracy during training\npyplot.subplot(212)\npyplot.title('Accuracy')\npyplot.plot(history.history['accuracy'], label='train')\npyplot.plot(history.history['val_accuracy'], label='test')\npyplot.legend()\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T23:09:53.880157Z","iopub.execute_input":"2021-08-16T23:09:53.880552Z","iopub.status.idle":"2021-08-16T23:09:54.174473Z","shell.execute_reply.started":"2021-08-16T23:09:53.880519Z","shell.execute_reply":"2021-08-16T23:09:54.1735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VIT model ","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.001\nweight_decay = 0.0001\nbatch_size = 64\nnum_epochs = 100\nimage_size = 1000  # We'll resize input images to this size\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 4\nmlp_head_units = [64, 32]  # Size of the dense layers of the final classifier","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:23:48.987137Z","iopub.execute_input":"2021-10-02T12:23:48.987582Z","iopub.status.idle":"2021-10-02T12:23:48.994763Z","shell.execute_reply.started":"2021-10-02T12:23:48.987544Z","shell.execute_reply":"2021-10-02T12:23:48.993496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Implement multilayer perceptron (MLP)\n","metadata":{}},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:24:57.835512Z","iopub.execute_input":"2021-10-02T12:24:57.836131Z","iopub.status.idle":"2021-10-02T12:24:57.840952Z","shell.execute_reply.started":"2021-10-02T12:24:57.836096Z","shell.execute_reply":"2021-10-02T12:24:57.840105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Implement patch creation as a layer\n","metadata":{}},{"cell_type":"code","source":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:25:03.418065Z","iopub.execute_input":"2021-10-02T12:25:03.418571Z","iopub.status.idle":"2021-10-02T12:25:03.42601Z","shell.execute_reply.started":"2021-10-02T12:25:03.418539Z","shell.execute_reply":"2021-10-02T12:25:03.425044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Implement the patch encoding layer\nThe PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. In addition, it adds a learnable position embedding to the projected vector.","metadata":{}},{"cell_type":"code","source":"class PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:25:05.270744Z","iopub.execute_input":"2021-10-02T12:25:05.271304Z","iopub.status.idle":"2021-10-02T12:25:05.280809Z","shell.execute_reply.started":"2021-10-02T12:25:05.271247Z","shell.execute_reply":"2021-10-02T12:25:05.279429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Build the ViT model\n","metadata":{}},{"cell_type":"code","source":"def create_vit_classifier():\n    inputs = layers.Input(shape=input_shape)\n    # Create patches.\n    patches = Patches(patch_size)(inputs)\n    # Encode patches.\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n\n    # Create multiple layers of the Transformer block.\n    for _ in range(transformer_layers):\n        # Layer normalization 1.\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n        # Create a multi-head attention layer.\n        attention_output = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n        )(x1, x1)\n        # Skip connection 1.\n        x2 = layers.Add()([attention_output, encoded_patches])\n        # Layer normalization 2.\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        # MLP.\n        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n        # Skip connection 2.\n        encoded_patches = layers.Add()([x3, x2])\n\n    # Create a [batch_size, projection_dim] tensor.\n    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n    representation = layers.Flatten()(representation)\n    representation = layers.Dropout(0.5)(representation)\n    # Add MLP.\n    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n    # Classify outputs.\n    logits = layers.Dense(1, activation='sigmoid')(features)\n    # Create the Keras model.\n    model = keras.Model(inputs=inputs, outputs=logits)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:25:09.464323Z","iopub.execute_input":"2021-10-02T12:25:09.464984Z","iopub.status.idle":"2021-10-02T12:25:09.475743Z","shell.execute_reply.started":"2021-10-02T12:25:09.464936Z","shell.execute_reply":"2021-10-02T12:25:09.474823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Compile, train, and evaluate the mode\n","metadata":{}},{"cell_type":"code","source":"def run_experiment(model):\n    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n\n    model.compile(\n        optimizer=opt,\n        loss='binary_crossentropy',\n        metrics=[ 'accuracy' ],\n    )\n\n    checkpoint_filepath = \"/tmp/checkpoint\"\n    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    history = model.fit(train_dataset, validation_data=validation_dataset, epochs = 5, batch_size = 64,callbacks=[checkpoint_callback])\n    model.load_weights(checkpoint_filepath)\n    return history\n\n\nvit_classifier = create_vit_classifier()\nprint(vit_classifier.summary())\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:25:13.115324Z","iopub.execute_input":"2021-10-02T12:25:13.115983Z","iopub.status.idle":"2021-10-02T12:25:14.823286Z","shell.execute_reply.started":"2021-10-02T12:25:13.115935Z","shell.execute_reply":"2021-10-02T12:25:14.822208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = run_experiment(vit_classifier)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T12:26:30.448519Z","iopub.execute_input":"2021-10-02T12:26:30.449171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}